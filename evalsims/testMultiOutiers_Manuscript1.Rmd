---
title: "Test multivariate outliers and cov. calculations manuscript 1"
author: "Katie Lotterhos"
date: "April 11, 2016"
output: html_document
---

```{r}
getwd() 
#
#setwd("/Users/katie/Desktop/MINOTAUReval/")
source("distanceFunctionsOther.R")
#source("misc/evalsims/ComparePlot.R")
source("GetAllMultiStats.R")
source("getEmpiricalP2.R")
library(qvalue)
#install.packages("devtools", dependencies=TRUE)
#install.packages("rrcovNA")
library(rrcovNA)
library(devtools)
install_github("NESCent/MINOTAUR@shinyDashboard")
library(MINOTAUR)
```

#### Non Parameteric Simulation Example
```{r}
  np <- read.csv("../data/df_inverse.csv")
  head(np)
  tail(np)
  nrow(np)
  np2 <- Getdf(np)
  col <- rep("grey", nrow(np2))
  pch <- rep(19, nrow(np2))
  cex <- rep(0.8, nrow(np2))
  col[1001:1002] <- "blue"
  pch[1001:1002] <- c(17,18)
  cex[1001:1002] <- 2
  ind <- c(1:1000/10000,.11,0.12)

png("../figures_man1/nonPara_dist.png", width=4, height=4, res=300, units="in")
  plot(np, col=col, pch=pch, cex=cex)
dev.off()

  plot(np, col=col, pch=pch, cex=cex)


png("../figures_man1/nonPara_log.png", width=10, height=12, res=300, units="in")
  make_nonPara_log <- function(){
  par(mfrow=c(4,3), mar=c(3,4,1,1), bty="l")
    plot(ind,log(np2$Md), col=col, pch=pch, ylab= "log(Mahalanobis)", cex=cex, xaxt="n")
      #abline(sort(log(dfv3.out$Md[dfv3.out$s==0]))[9900*0.999],0)
      #text(0,1.5, "A", cex=2)
    plot(0,0, xaxt="n", yaxt="n")
    plot(density(np2$Md), main="")

    plot(ind,log(np2$Hd_var), col=col, pch=pch, ylab= "log(Harmonic mean dist.)(var)", cex=cex, xaxt="n")
      #abline(sort(log(dfv3.out$Hd[dfv3.out$s==0]))[9900*0.999],0)
      #text(0,1.5, "B", cex=2)
      #text(0,2.3,round(getEmpPower(dfv3.out$Hd,dfv3.out$s_high==0),2))
    plot(ind,log(np2$Hd_cov), col=col, pch=pch, ylab= "log(Harmonic mean dist.)(cov)", cex=cex, xaxt="n")
     plot(density(np2$Hd_cov), main="")


    plot(ind, log(np2$Kd_var), col=col, pch=pch, ylab= "log(Kernel density) (var)", cex=cex, xaxt="n")
      #abline(sort(log(dfv3.out$Kd[dfv3.out$s==0]))[9900*0.999],0)
      #text(0,4.0, "C", cex=2)
      #text(0,4.1,round(getEmpPower(dfv3.out$Kd,dfv3.out$s_high==0),2))
    plot(ind, log(np2$Kd_cov), col=col, pch=pch, ylab= "log(Kernel density) (cov)", cex=cex, xaxt="n")
    plot(density(np2$Kd_cov), main="") 

    plot(ind, log(np2$Nd_var), col=col, pch=pch, ylab= "log(Nearest neighbor)(var)", cex=cex, xaxt="n")
      #abline(sort(log(dfv3.out$Nd[dfv3.out$s==0]))[9900*0.999],0)
      #text(0,0, "D", cex=2)
      #text(0,0.1,round(getEmpPower(dfv3.out$Nd,dfv3.out$s_high==0),2))
    plot(ind, log(np2$Nd_cov), col=col, pch=pch, ylab= "log(Nearest neighbor)(cov)", cex=cex, xaxt="n")
    plot(density(np2$Nd_cov), main="") 
}
dev.off()
make_nonPara_log()
```

### Two refugia example

Load data and output dataframe with two kinds of multivariate stats: one that only standardizes by the variance in each dimension, and one that standardizes by the variance-covariance matrix (for three functions: harmonicDist, neighborDist, and kernelDist.)  The `Getdf()` function uses kernelDeviance to calculate the best bandwidth.


```{r}
  d1 <- read.table("~/Google Drive/MultiOutlierVisualization/practiceData/KatieSims/2R_R30_1351142970_988_6_NumPops=30_NumInd=20Bayenv2LFMMpca.Cpval", header=TRUE)
  head(d1)
  dfv <- d1[c(1,3,4,5,10,12,13,15:17,34)]
  dim(dfv)
  head(dfv)
  #dfv2 <- dfv[dfv$SNPIncluded,]
  colnums <- 8:11
  #head(dfv)
  #str(dfv)
  #cbind(colnames(dfv))

  table(dfv$s_high)
  names(dfv)[colnums]
  dfv2.out <- Getdf(dfv, colnums)

  dim(dfv)
  dim(dfv2.out)
  head(dfv2.out)
  dfv3.out <- dfv2.out[,-c(12:13, 15, 17, 19)]
  head(dfv3.out)
 #write.table(dfv3.out, "../data/TwoRefSimForShiny.txt",row.names=FALSE)

  head(dfv3.out)
```

### Set color levels for plotting
```{r}
 col <- factor(dfv2.out$s_high)
  levels(col) = c("grey",  "#9ad0f3", "#0072B2", "#D55E00")
  col <- as.character(col)
  ind <- c(1:9900/100, 100:199)
  cex <- c(rep(0.8, 9900), rep(1.1, 100))
  pch <- c(rep(19, 9900), rep(17, 100))
```

### Plot univariate Distributions of Two Ref model

```{r}
  png("figures_man1/TwoRefUnivarDist.png", width=6, height=6, res=450, units="in")
  plot_TwoRefUnivarDist<-function(){
    dplot <- dfv[,colnums]
    dplot[,2] <- abs(dplot[,2]) #abs for rho
    names <- c("log(Bayes Factor)", "Spearman's rho", "XTX", "Z-Score")
    colnames(dplot)
    par(mfrow=c(3,3), mar=c(3,3,0,0), oma=c(1,1,1,1))
      # (1,1) BF vs rho
      plot(dplot[,1], dplot[,2], col=col, pch=pch, bty="n")
        mtext("Bayes Factor", side=1, line=2.5, cex=1)
        mtext("Spearman's rho", side=2, line=2.5, cex=1)
      # (1,2) XTX vs rho
      plot(dplot[,3], dplot[,2], col=col, pch=pch, bty="n")
      # (1,3) Z vs rhow
      plot(dplot[,4], dplot[,2], col=col, pch=pch, bty="n")
      # (2, 1) blank
      plot(NULL, NULL, xlim=c(0,1), ylim=c(0,1), xaxt="n", yaxt="n", bty="n")
      # (2,2) XTX vs BF
      plot(dplot[,3], dplot[,1], col=col, pch=pch, bty="n")
        mtext("XTX", side=1, line=2.5, cex=1)
        mtext("Bayes Factor", side=2, line=2.5, cex=1)
      # (2,3) Z vs BF
      plot(dplot[,4], dplot[,1], col=col, pch=pch, bty="n")
      # (3, 1) blank
      plot(NULL, NULL, xlim=c(0,1), ylim=c(0,1), xaxt="n", yaxt="n", bty="n")
      # (3, 2) blank
      plot(NULL, NULL, xlim=c(0,1), ylim=c(0,1), xaxt="n", yaxt="n", bty="n")
      # (2,3) Z vs XTX
      plot(dplot[,4], dplot[,3], col=col, pch=pch, bty="n")
          mtext("Z-score", side=1, line=2.5, cex=1)
          mtext("XTX", side=2, line=2.5, cex=1)
    }
    dev.off()
    
  plot_TwoRefUnivarDist()  
```

### Plot Two Ref example Correcting for Variances ####
```{r}
#png("figures_man1/TwoRef_log_var.png", width=10, height=8, res=450, units="in")
   par(mfrow=c(2,2), mar=c(3,4,1,1), bty="l")
    plot(ind, log(dfv2.out$Md), col=col, pch=pch, ylab= "log(Mahalanobis)", cex=cex)
      abline(sort(log(dfv2.out$Md[dfv2.out$s==0]))[9900*0.999],0)
      text(0,3, "A", cex=2)
      text(20,3,round(getEmpPower(dfv2.out$Md,dfv2.out$s_high==0),2))
      legend(125, 0, legend=c("Neutral", "s = 0.005", "s=0.01", "s=0.1"),
             pch=c(19, 17, 17,17), col=c("grey",  "#9ad0f3", "#0072B2", "#D55E00"))

    plot(ind, log(dfv2.out$Hd_var), col=col, pch=pch, ylab= "log(Harmonic mean dist.)", cex=cex)
      abline(sort(log(dfv2.out$Hd_var[dfv2.out$s==0]))[9900*0.999],0)
      text(0,3.1, "B", cex=2)
      text(20,3.1,round(getEmpPower(dfv2.out$Hd_var,dfv2.out$s_high==0),2))

    plot(ind, log(dfv2.out$Kd_var), col=col, pch=pch, ylab= "log(Kernel density)", cex=cex)
      abline(sort(log(dfv2.out$Kd_var[dfv2.out$s==0]))[9900*0.999],0)
      text(0,6, "C", cex=2)
      text(20,6,round(getEmpPower(dfv2.out$Kd_var,dfv2.out$s_high==0),2))

    plot(ind, log(dfv2.out$Nd_var), col=col, pch=pch, ylab= "log(Nearest neighbor)", cex=cex)
      abline(sort(log(dfv2.out$Nd_var[dfv2.out$s==0]))[9900*0.999],0)
      text(0,1.5, "D", cex=2)
      text(20,1.5,round(getEmpPower(dfv2.out$Nd_var,dfv2.out$s_high==0),2))

#  dev.off()
```


### Plot Two Ref example Correcting for COVariances

```{r}
 # png("figures_man1/TwoRef_log_cov.png", width=10, height=8, res=450, units="in")
   par(mfrow=c(2,2), mar=c(3,4,1,1), bty="l")
    plot(ind, log(dfv2.out$Md), col=col, pch=pch, ylab= "log(Mahalanobis)", cex=cex)
      abline(sort(log(dfv2.out$Md[dfv2.out$s==0]))[9900*0.999],0)
      text(0,3, "A", cex=2)
      text(20,3,round(getEmpPower(dfv2.out$Md,dfv2.out$s_high==0),2))
      legend(125, 0, legend=c("Neutral", "s = 0.005", "s=0.01", "s=0.1"),
             pch=c(19, 17, 17,17), col=c("grey",  "#9ad0f3", "#0072B2", "#D55E00"))

    plot(ind, log(dfv2.out$Hd_cov), col=col, pch=pch, ylab= "log(Harmonic mean dist.)", cex=cex)
      abline(sort(log(dfv2.out$Hd_cov[dfv2.out$s==0]))[9900*0.999],0)
      text(0,3.1, "B", cex=2)
      text(20,3.1,round(getEmpPower(dfv2.out$Hd_cov,dfv2.out$s_high==0),2))

    plot(ind, log(dfv2.out$Kd_cov), col=col, pch=pch, ylab= "log(Kernel density)", cex=cex)
      abline(sort(log(dfv2.out$Kd_cov[dfv2.out$s==0]))[9900*0.999],0)
      text(0,6, "C", cex=2)
      text(20,6,round(getEmpPower(dfv2.out$Kd_cov,dfv2.out$s_high==0),2))

    plot(ind, log(dfv2.out$Nd_cov), col=col, pch=pch, ylab= "log(Nearest neighbor)", cex=cex)
      abline(sort(log(dfv2.out$Nd_cov[dfv2.out$s==0]))[9900*0.999],0)
      text(0,1.5, "D", cex=2)
      text(20,1.5,round(getEmpPower(dfv2.out$Nd_cov,dfv2.out$s_high==0),2))
}
  dev.off()

```

From the above example, you can see that the covariance correction actually makes things alot WORSE, especially for the harmonicDist.  Why does this happen?  Because the selected loci, although only < 1% of the dataset, bias the estimation of the covariance among the univariate statistics.

#### Compare covariance of all data to just neutral data

```{r}
  # Covariance matrix of all data
    S <- cov(dfv[!is.na(rowSums(dfv[,colnums])),colnums])
    S
    solve(S)
  # Covariance of neutral loci
    Sneut <- cov(dfv[dfv$s_high==0,colnums])
    Sneut
    solve(Sneut)
  par(mfrow=c(1,1), mar=c(4,4,1,1))
  plot(log(Sneut), log(S)); abline(0,1)
```

#### Test the power of the neutral covariance matrix

```{r}
  #test power of neutral covariance
    S_inv <- solve(Sneut)
    df.vars <- as.matrix(dfv[!is.na(rowSums(dfv[,colnums])),colnums,drop=FALSE])
    n <- nrow(df.vars)
    d <- ncol(df.vars)
     distances <- C_harmonicDist2(split(t(df.vars),1:d), split(S_inv,1:d))$distance
    par(mfrow=c(1,1))
    plot(ind[-1], log(distances), col=col, cex=cex, pch=pch)
    abline(sort(log(distances[dfv2.out$s==0]))[9900*0.999],0)
    text(20,3.1,round(getEmpPower(distances,(dfv2.out$s_high==0)[-1]),2))

```

The above result illustrates that if the covariance was representative of neutral loci, power could be increased substantially for the tests.  To explore this idea, I used the function CovNAMcd from the rrcovNA package.  It computes a robust multivariate location and scatter estimate with a high breakdown point for incomplete data, using the ‘Fast MCD’ (Minimum Covariance Determinant) estimator. This could also be beneficial for datasets with a lot of NAs.

#### Compare CovNAMcd to 
```{r}
  S_mcd <- CovNAMcd(dfv[,colnums])
  S_mcd
  Sneut_mcd <- CovNAMcd(dfv[dfv$s_high==0,colnums])
  Sneut_mcd 
  str(S_mcd@cov)

# Compare cov of neutral data to cov_mcd of all data
  plot(log(Sneut), log(S_mcd@cov)); abline(0,1)

# Compare cov_mcd of all data to cov_mcd of neutral data
  plot(log(Sneut_mcd@cov), log(S_mcd@cov)); abline(0,1)
```

It is interesting how the robust covariance is not affected at all by the selected loci in the dataset!  How does this apply to our multivariate outlier approach:

```{r}
   S_inv <- solve(S_mcd@cov)
    df.vars <- as.matrix(dfv[!is.na(rowSums(dfv[,colnums])),colnums,drop=FALSE])
    n <- nrow(df.vars)
    d <- ncol(df.vars)
     distances <- C_harmonicDist2(split(t(df.vars),1:d), split(S_inv,1:d))$distance
    par(mfrow=c(1,1))
    plot(ind[-1], log(distances), col=col, cex=cex, pch=pch)
    abline(sort(log(distances[dfv2.out$s==0]))[9900*0.999],0)
    text(20,4.1,round(getEmpPower(distances,(dfv2.out$s_high==0)[-1]),2))
```

The robust covariance is still not as good as ignoring the covariance all together, and just using the variance calculation... but it will be interesting to see for other statistics.  For Mahalanobis:

```{r}
  diff <- df.vars
  for (i in 1:ncol(df.vars)) {
    diff[,i] <- diff[,i] - mean(diff[,i], na.rm=TRUE)
  }
  distances2 <- sqrt( rowSums((diff %*% solve(S_mcd@cov))*diff) )

plot(ind[-1], log(distances2), col=col, cex=cex, pch=pch)
    abline(sort(log(distances2[dfv2.out$s==0]))[9900*0.999],0)
    text(20,4.1,round(getEmpPower(distances2,(dfv2.out$s_high==0)[-1]),2))

```

So it improves things quite a bit for Mahalonobis!